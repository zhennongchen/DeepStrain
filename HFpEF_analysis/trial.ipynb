{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.rand(50,10) + 10\n",
    "X2 = torch.rand(50,10) \n",
    "X = torch.cat((X1,X2),0)\n",
    "\n",
    "Y1 = torch.randint(1,2,(50,1))\n",
    "Y2 = torch.randint(0,1,(50,1))\n",
    "Y = torch.cat((Y1,Y2),0).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)  # Output size is 1 for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.linear(x))  # Sigmoid activation for binary classification\n",
    "        return out\n",
    "    \n",
    "# Instantiate the model\n",
    "input_size = 58  # Number of features\n",
    "model = LogisticRegression(input_size)\n",
    "\n",
    "# Binary cross-entropy loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Stochastic Gradient Descent optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 1000000\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = '/mnt/mount_zc_NAS/Deepstrain/HFpEF_analysis/models/best_model.pt'  # Path to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([45, 21, 31, 12, 23, 13, 49, 47, 16, 39, 29, 28,  0, 44, 22,  1, 11,  5,\n",
      "        19, 37, 27, 35, 10, 20, 36, 18, 25, 34, 42,  7, 15,  2, 24, 43, 32, 17,\n",
      "         8, 48, 46, 33, 41, 30,  9, 40,  4, 14,  6,  3, 26, 38])\n",
      "tensor([0., 1.])\n",
      "Epoch [1000/1000000], Loss: 1.717844009399414  train acc, sen, spec:  0.625 1.0 0.3076923076923077  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [2000/1000000], Loss: 1.5507246255874634  train acc, sen, spec:  0.625 0.9545454545454546 0.34615384615384615  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [3000/1000000], Loss: 1.4321078062057495  train acc, sen, spec:  0.6458333333333334 0.9545454545454546 0.38461538461538464  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [4000/1000000], Loss: 1.3278610706329346  train acc, sen, spec:  0.6041666666666666 0.9545454545454546 0.3076923076923077  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [5000/1000000], Loss: 1.2444707155227661  train acc, sen, spec:  0.6041666666666666 0.9545454545454546 0.3076923076923077  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [6000/1000000], Loss: 1.1814942359924316  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [7000/1000000], Loss: 1.1321748495101929  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [8000/1000000], Loss: 1.0916656255722046  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [9000/1000000], Loss: 1.057321548461914  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [10000/1000000], Loss: 1.0275431871414185  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [11000/1000000], Loss: 1.001299262046814  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [12000/1000000], Loss: 0.9778539538383484  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [13000/1000000], Loss: 0.9567262530326843  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [14000/1000000], Loss: 0.9375552535057068  train acc, sen, spec:  0.6666666666666666 0.9545454545454546 0.4230769230769231  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [15000/1000000], Loss: 0.9200988411903381  train acc, sen, spec:  0.6875 0.9545454545454546 0.46153846153846156  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [16000/1000000], Loss: 0.9041197299957275  train acc, sen, spec:  0.6875 0.9545454545454546 0.46153846153846156  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [17000/1000000], Loss: 0.8894453048706055  train acc, sen, spec:  0.6875 0.9545454545454546 0.46153846153846156  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [18000/1000000], Loss: 0.8759191632270813  train acc, sen, spec:  0.6875 0.9545454545454546 0.46153846153846156  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [19000/1000000], Loss: 0.8634123802185059  train acc, sen, spec:  0.6666666666666666 0.9090909090909091 0.46153846153846156  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [20000/1000000], Loss: 0.8518030047416687  train acc, sen, spec:  0.6875 0.9090909090909091 0.5  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [21000/1000000], Loss: 0.8409993052482605  train acc, sen, spec:  0.6875 0.9090909090909091 0.5  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [22000/1000000], Loss: 0.8309038281440735  train acc, sen, spec:  0.6875 0.9090909090909091 0.5  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [23000/1000000], Loss: 0.8214535117149353  train acc, sen, spec:  0.6875 0.9090909090909091 0.5  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [24000/1000000], Loss: 0.8125941753387451  train acc, sen, spec:  0.6875 0.9090909090909091 0.5  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [25000/1000000], Loss: 0.8042609691619873  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [26000/1000000], Loss: 0.7964094281196594  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [27000/1000000], Loss: 0.7890097498893738  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [28000/1000000], Loss: 0.7820188403129578  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [29000/1000000], Loss: 0.7754063010215759  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [30000/1000000], Loss: 0.7691541314125061  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [31000/1000000], Loss: 0.7632320523262024  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [32000/1000000], Loss: 0.7576177716255188  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [33000/1000000], Loss: 0.752305269241333  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [34000/1000000], Loss: 0.7472574710845947  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [35000/1000000], Loss: 0.7424724698066711  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [36000/1000000], Loss: 0.737923800945282  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [37000/1000000], Loss: 0.7336032390594482  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [38000/1000000], Loss: 0.7294923663139343  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [39000/1000000], Loss: 0.7255842685699463  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [40000/1000000], Loss: 0.7218634486198425  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [41000/1000000], Loss: 0.7183184623718262  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [42000/1000000], Loss: 0.7149328589439392  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [43000/1000000], Loss: 0.711702823638916  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [44000/1000000], Loss: 0.7086164951324463  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [45000/1000000], Loss: 0.7056590914726257  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [46000/1000000], Loss: 0.7028324007987976  train acc, sen, spec:  0.7291666666666666 0.9545454545454546 0.5384615384615384  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [47000/1000000], Loss: 0.7001216411590576  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [48000/1000000], Loss: 0.6975212097167969  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [49000/1000000], Loss: 0.6950273513793945  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [50000/1000000], Loss: 0.692629337310791  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [51000/1000000], Loss: 0.6903190016746521  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [52000/1000000], Loss: 0.688100278377533  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [53000/1000000], Loss: 0.6859536170959473  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [54000/1000000], Loss: 0.6838863492012024  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [55000/1000000], Loss: 0.6818866729736328  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [56000/1000000], Loss: 0.6799576878547668  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [57000/1000000], Loss: 0.6780872344970703  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [58000/1000000], Loss: 0.6762813925743103  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [59000/1000000], Loss: 0.6745264530181885  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [60000/1000000], Loss: 0.6728253960609436  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [61000/1000000], Loss: 0.671176016330719  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [62000/1000000], Loss: 0.6695747375488281  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [63000/1000000], Loss: 0.6680135726928711  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [64000/1000000], Loss: 0.6664994359016418  train acc, sen, spec:  0.75 0.9545454545454546 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [65000/1000000], Loss: 0.6650211215019226  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [66000/1000000], Loss: 0.6635835766792297  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [67000/1000000], Loss: 0.6621832847595215  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [68000/1000000], Loss: 0.6608155369758606  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [69000/1000000], Loss: 0.6594788432121277  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [70000/1000000], Loss: 0.658177375793457  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [71000/1000000], Loss: 0.656904399394989  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [72000/1000000], Loss: 0.6556572914123535  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [73000/1000000], Loss: 0.6544468998908997  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [74000/1000000], Loss: 0.6532543301582336  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [75000/1000000], Loss: 0.6520870327949524  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [76000/1000000], Loss: 0.6509483456611633  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [77000/1000000], Loss: 0.6498274207115173  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [78000/1000000], Loss: 0.6487336754798889  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [79000/1000000], Loss: 0.6476554870605469  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [80000/1000000], Loss: 0.6466005444526672  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [81000/1000000], Loss: 0.6455634832382202  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [82000/1000000], Loss: 0.6445488333702087  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [83000/1000000], Loss: 0.6435513496398926  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [84000/1000000], Loss: 0.6425725817680359  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [85000/1000000], Loss: 0.6416026949882507  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [86000/1000000], Loss: 0.6406562328338623  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [87000/1000000], Loss: 0.6397230625152588  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [88000/1000000], Loss: 0.6388081312179565  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [89000/1000000], Loss: 0.6379041075706482  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [90000/1000000], Loss: 0.637016236782074  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [91000/1000000], Loss: 0.636139452457428  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [92000/1000000], Loss: 0.6352792382240295  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [93000/1000000], Loss: 0.6344330310821533  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [94000/1000000], Loss: 0.6335914731025696  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [95000/1000000], Loss: 0.632770836353302  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [96000/1000000], Loss: 0.6319584846496582  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [97000/1000000], Loss: 0.631158173084259  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [98000/1000000], Loss: 0.630370557308197  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [99000/1000000], Loss: 0.6295871734619141  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [100000/1000000], Loss: 0.6288248896598816  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [101000/1000000], Loss: 0.628058135509491  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [102000/1000000], Loss: 0.627312958240509  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [103000/1000000], Loss: 0.626569926738739  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [104000/1000000], Loss: 0.6258363127708435  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [105000/1000000], Loss: 0.6251204013824463  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [106000/1000000], Loss: 0.6244078278541565  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [107000/1000000], Loss: 0.6237032413482666  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [108000/1000000], Loss: 0.6230077147483826  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [109000/1000000], Loss: 0.6223229765892029  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [110000/1000000], Loss: 0.6216480135917664  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [111000/1000000], Loss: 0.6209720373153687  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [112000/1000000], Loss: 0.6203088760375977  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [113000/1000000], Loss: 0.6196535229682922  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [114000/1000000], Loss: 0.6190032362937927  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [115000/1000000], Loss: 0.6183568835258484  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [116000/1000000], Loss: 0.6177246570587158  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [117000/1000000], Loss: 0.6170969605445862  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [118000/1000000], Loss: 0.6164771914482117  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [119000/1000000], Loss: 0.6158564686775208  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [120000/1000000], Loss: 0.6152441501617432  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [121000/1000000], Loss: 0.6146392226219177  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [122000/1000000], Loss: 0.6140467524528503  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [123000/1000000], Loss: 0.6134585738182068  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [124000/1000000], Loss: 0.6128796935081482  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [125000/1000000], Loss: 0.6122915148735046  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [126000/1000000], Loss: 0.6117112040519714  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [127000/1000000], Loss: 0.6111467480659485  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [128000/1000000], Loss: 0.6105827689170837  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [129000/1000000], Loss: 0.6100243926048279  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [130000/1000000], Loss: 0.6094700694084167  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [131000/1000000], Loss: 0.6089224815368652  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [132000/1000000], Loss: 0.6083738803863525  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [133000/1000000], Loss: 0.607835590839386  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [134000/1000000], Loss: 0.6072993874549866  train acc, sen, spec:  0.7083333333333334 0.8636363636363636 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [135000/1000000], Loss: 0.6067724823951721  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [136000/1000000], Loss: 0.6062536835670471  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [137000/1000000], Loss: 0.6057322025299072  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [138000/1000000], Loss: 0.6052170395851135  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [139000/1000000], Loss: 0.6046993136405945  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [140000/1000000], Loss: 0.6041900515556335  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [141000/1000000], Loss: 0.6036856174468994  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [142000/1000000], Loss: 0.6031821370124817  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [143000/1000000], Loss: 0.6026818156242371  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [144000/1000000], Loss: 0.602191686630249  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [145000/1000000], Loss: 0.6017029285430908  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [146000/1000000], Loss: 0.6012231707572937  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [147000/1000000], Loss: 0.600744903087616  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [148000/1000000], Loss: 0.6002665162086487  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [149000/1000000], Loss: 0.5997962951660156  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [150000/1000000], Loss: 0.5993247628211975  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [151000/1000000], Loss: 0.5988540053367615  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [152000/1000000], Loss: 0.5983870029449463  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [153000/1000000], Loss: 0.5979281663894653  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [154000/1000000], Loss: 0.5974693894386292  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [155000/1000000], Loss: 0.5970141291618347  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [156000/1000000], Loss: 0.5965617895126343  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [157000/1000000], Loss: 0.59610915184021  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [158000/1000000], Loss: 0.5956632494926453  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [159000/1000000], Loss: 0.5952240228652954  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [160000/1000000], Loss: 0.5947853922843933  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [161000/1000000], Loss: 0.5943499207496643  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [162000/1000000], Loss: 0.5939150452613831  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [163000/1000000], Loss: 0.5934844613075256  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [164000/1000000], Loss: 0.5930605530738831  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [165000/1000000], Loss: 0.5926299095153809  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [166000/1000000], Loss: 0.5922095775604248  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [167000/1000000], Loss: 0.5917938351631165  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [168000/1000000], Loss: 0.591376006603241  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [169000/1000000], Loss: 0.5909588932991028  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [170000/1000000], Loss: 0.5905469655990601  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [171000/1000000], Loss: 0.5901377201080322  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [172000/1000000], Loss: 0.5897350907325745  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [173000/1000000], Loss: 0.5893266201019287  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [174000/1000000], Loss: 0.5889267921447754  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [175000/1000000], Loss: 0.5885283350944519  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [176000/1000000], Loss: 0.5881345868110657  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [177000/1000000], Loss: 0.587733805179596  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [178000/1000000], Loss: 0.5873394012451172  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [179000/1000000], Loss: 0.5869524478912354  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [180000/1000000], Loss: 0.5865535140037537  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [181000/1000000], Loss: 0.5861716270446777  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [182000/1000000], Loss: 0.5857881903648376  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [183000/1000000], Loss: 0.5854045748710632  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [184000/1000000], Loss: 0.5850203633308411  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [185000/1000000], Loss: 0.5846424698829651  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [186000/1000000], Loss: 0.5842666625976562  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [187000/1000000], Loss: 0.5838921666145325  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [188000/1000000], Loss: 0.5835139155387878  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [189000/1000000], Loss: 0.5831524729728699  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [190000/1000000], Loss: 0.5827805399894714  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [191000/1000000], Loss: 0.5824155807495117  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [192000/1000000], Loss: 0.5820510387420654  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [193000/1000000], Loss: 0.5816959142684937  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [194000/1000000], Loss: 0.5813273787498474  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [195000/1000000], Loss: 0.5809664130210876  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [196000/1000000], Loss: 0.5806112289428711  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [197000/1000000], Loss: 0.5802538990974426  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [198000/1000000], Loss: 0.5798932909965515  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [199000/1000000], Loss: 0.5795395970344543  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [200000/1000000], Loss: 0.5791910886764526  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [201000/1000000], Loss: 0.5788476467132568  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [202000/1000000], Loss: 0.578491747379303  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [203000/1000000], Loss: 0.5781468749046326  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [204000/1000000], Loss: 0.5778008699417114  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [205000/1000000], Loss: 0.5774635076522827  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [206000/1000000], Loss: 0.57711261510849  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [207000/1000000], Loss: 0.5767796039581299  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [208000/1000000], Loss: 0.5764374732971191  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [209000/1000000], Loss: 0.5761037468910217  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [210000/1000000], Loss: 0.5757682919502258  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [211000/1000000], Loss: 0.5754299163818359  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [212000/1000000], Loss: 0.5751035809516907  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [213000/1000000], Loss: 0.574772298336029  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [214000/1000000], Loss: 0.574436366558075  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [215000/1000000], Loss: 0.5741090774536133  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [216000/1000000], Loss: 0.5737813115119934  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [217000/1000000], Loss: 0.5734519958496094  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [218000/1000000], Loss: 0.5731287002563477  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [219000/1000000], Loss: 0.572805643081665  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [220000/1000000], Loss: 0.5724881291389465  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [221000/1000000], Loss: 0.572163999080658  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [222000/1000000], Loss: 0.5718414783477783  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [223000/1000000], Loss: 0.5715301632881165  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [224000/1000000], Loss: 0.5712130069732666  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [225000/1000000], Loss: 0.5709006190299988  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [226000/1000000], Loss: 0.5705839991569519  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [227000/1000000], Loss: 0.5702722072601318  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [228000/1000000], Loss: 0.5699610710144043  train acc, sen, spec:  0.7291666666666666 0.9090909090909091 0.5769230769230769  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [229000/1000000], Loss: 0.5696532726287842  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [230000/1000000], Loss: 0.5693420767784119  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [231000/1000000], Loss: 0.5690348148345947  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [232000/1000000], Loss: 0.5687196850776672  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [233000/1000000], Loss: 0.5684118866920471  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [234000/1000000], Loss: 0.5681083798408508  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [235000/1000000], Loss: 0.567798912525177  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [236000/1000000], Loss: 0.5674901008605957  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [237000/1000000], Loss: 0.5671786069869995  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [238000/1000000], Loss: 0.5668848156929016  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [239000/1000000], Loss: 0.5665852427482605  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [240000/1000000], Loss: 0.566284716129303  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [241000/1000000], Loss: 0.5659805536270142  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [242000/1000000], Loss: 0.5656806826591492  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [243000/1000000], Loss: 0.5653871297836304  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [244000/1000000], Loss: 0.5650917887687683  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [245000/1000000], Loss: 0.5647952556610107  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [246000/1000000], Loss: 0.5645008683204651  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [247000/1000000], Loss: 0.5642064809799194  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [248000/1000000], Loss: 0.5639146566390991  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [249000/1000000], Loss: 0.5636165142059326  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [250000/1000000], Loss: 0.5633318424224854  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [251000/1000000], Loss: 0.5630390644073486  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [252000/1000000], Loss: 0.5627499222755432  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [253000/1000000], Loss: 0.5624729990959167  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [254000/1000000], Loss: 0.5621839165687561  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [255000/1000000], Loss: 0.5619056224822998  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [256000/1000000], Loss: 0.561619758605957  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [257000/1000000], Loss: 0.5613341927528381  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [258000/1000000], Loss: 0.5610623359680176  train acc, sen, spec:  0.75 0.9090909090909091 0.6153846153846154  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [259000/1000000], Loss: 0.5607827305793762  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [260000/1000000], Loss: 0.5604999661445618  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [261000/1000000], Loss: 0.5602275729179382  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [262000/1000000], Loss: 0.5599498152732849  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [263000/1000000], Loss: 0.5596749186515808  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [264000/1000000], Loss: 0.5593991279602051  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [265000/1000000], Loss: 0.5591257214546204  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [266000/1000000], Loss: 0.558844804763794  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [267000/1000000], Loss: 0.558565080165863  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [268000/1000000], Loss: 0.5582962036132812  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [269000/1000000], Loss: 0.5580156445503235  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [270000/1000000], Loss: 0.5577395558357239  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [271000/1000000], Loss: 0.5574733018875122  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [272000/1000000], Loss: 0.5571914315223694  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [273000/1000000], Loss: 0.556915819644928  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [274000/1000000], Loss: 0.556644856929779  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [275000/1000000], Loss: 0.5563772320747375  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [276000/1000000], Loss: 0.556105375289917  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [277000/1000000], Loss: 0.5558351874351501  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [278000/1000000], Loss: 0.5555669665336609  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [279000/1000000], Loss: 0.5553011894226074  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [280000/1000000], Loss: 0.5550262331962585  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [281000/1000000], Loss: 0.5547671318054199  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [282000/1000000], Loss: 0.5544957518577576  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [283000/1000000], Loss: 0.5542410612106323  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [284000/1000000], Loss: 0.5539766550064087  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [285000/1000000], Loss: 0.5537053346633911  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [286000/1000000], Loss: 0.5534489154815674  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [287000/1000000], Loss: 0.5531871318817139  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [288000/1000000], Loss: 0.5529279112815857  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [289000/1000000], Loss: 0.5526685118675232  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [290000/1000000], Loss: 0.5524075627326965  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [291000/1000000], Loss: 0.5521448254585266  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [292000/1000000], Loss: 0.5518854260444641  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [293000/1000000], Loss: 0.5516350865364075  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [294000/1000000], Loss: 0.551373302936554  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [295000/1000000], Loss: 0.5511130094528198  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [296000/1000000], Loss: 0.5508580803871155  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [297000/1000000], Loss: 0.5506053566932678  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [298000/1000000], Loss: 0.5503542423248291  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [299000/1000000], Loss: 0.5501044392585754  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [300000/1000000], Loss: 0.5498489737510681  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [301000/1000000], Loss: 0.5496038198471069  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [302000/1000000], Loss: 0.5493490099906921  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [303000/1000000], Loss: 0.5490975975990295  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [304000/1000000], Loss: 0.5488584637641907  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [305000/1000000], Loss: 0.5486044883728027  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [306000/1000000], Loss: 0.548362672328949  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [307000/1000000], Loss: 0.5481165051460266  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [308000/1000000], Loss: 0.5478765964508057  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [309000/1000000], Loss: 0.5476285219192505  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [310000/1000000], Loss: 0.5473840236663818  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [311000/1000000], Loss: 0.5471380352973938  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [312000/1000000], Loss: 0.5468966364860535  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [313000/1000000], Loss: 0.5466507077217102  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [314000/1000000], Loss: 0.5463948249816895  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [315000/1000000], Loss: 0.5461497902870178  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [316000/1000000], Loss: 0.5459165573120117  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [317000/1000000], Loss: 0.5456685423851013  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [318000/1000000], Loss: 0.5454287528991699  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [319000/1000000], Loss: 0.5451751351356506  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [320000/1000000], Loss: 0.5449297428131104  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [321000/1000000], Loss: 0.5446903705596924  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [322000/1000000], Loss: 0.54445481300354  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [323000/1000000], Loss: 0.544212281703949  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [324000/1000000], Loss: 0.5439689755439758  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [325000/1000000], Loss: 0.5437355041503906  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [326000/1000000], Loss: 0.5434994697570801  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [327000/1000000], Loss: 0.5432538390159607  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [328000/1000000], Loss: 0.543018102645874  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [329000/1000000], Loss: 0.5427730679512024  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [330000/1000000], Loss: 0.5425397157669067  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [331000/1000000], Loss: 0.542307436466217  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [332000/1000000], Loss: 0.5420729517936707  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [333000/1000000], Loss: 0.5418389439582825  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [334000/1000000], Loss: 0.5416016578674316  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [335000/1000000], Loss: 0.5413606762886047  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [336000/1000000], Loss: 0.5411249995231628  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [337000/1000000], Loss: 0.5408987998962402  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [338000/1000000], Loss: 0.5406585335731506  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [339000/1000000], Loss: 0.540432870388031  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [340000/1000000], Loss: 0.5401928424835205  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [341000/1000000], Loss: 0.53995680809021  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [342000/1000000], Loss: 0.5397273898124695  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [343000/1000000], Loss: 0.5394892692565918  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [344000/1000000], Loss: 0.5392554998397827  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [345000/1000000], Loss: 0.5390334129333496  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [346000/1000000], Loss: 0.5387986302375793  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [347000/1000000], Loss: 0.5385777950286865  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [348000/1000000], Loss: 0.5383384227752686  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [349000/1000000], Loss: 0.5381179451942444  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [350000/1000000], Loss: 0.5378843545913696  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [351000/1000000], Loss: 0.5376583933830261  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [352000/1000000], Loss: 0.5374450087547302  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [353000/1000000], Loss: 0.5372008681297302  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [354000/1000000], Loss: 0.5369670391082764  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [355000/1000000], Loss: 0.5367359519004822  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [356000/1000000], Loss: 0.5365181565284729  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [357000/1000000], Loss: 0.5362926721572876  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [358000/1000000], Loss: 0.5360623002052307  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [359000/1000000], Loss: 0.5358433127403259  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [360000/1000000], Loss: 0.5356149077415466  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [361000/1000000], Loss: 0.5353879332542419  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [362000/1000000], Loss: 0.5351588726043701  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [363000/1000000], Loss: 0.5349337458610535  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n",
      "Epoch [364000/1000000], Loss: 0.5347087383270264  train acc, sen, spec:  0.7708333333333334 0.9090909090909091 0.6538461538461539  val acc, sen, spec:  1.0 1.0 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Save the best model based on validation loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# if loss.item() < best_val_loss and epoch % 2000 == 0:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     best_val_loss = loss.item()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f67707534227d/workspace/Documents/DeepStrain/HFpEF_analysis/trial.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#     torch.save(model.state_dict(), best_model_path)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:193\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[1;32m    190\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[1;32m    192\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[0;32m--> 193\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:89\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mnumel() \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     88\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39;49mones_like(out, memory_format\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpreserve_format))\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# shuffle X and Y\n",
    "idx = torch.randperm(50)\n",
    "print(idx)\n",
    "X = X[idx,:]\n",
    "Y = Y[idx]\n",
    "\n",
    "\n",
    "X_train = X[0:48,:]\n",
    "Y_train = Y[0:48]\n",
    "\n",
    "X_val = X[48:,:]\n",
    "Y_val = Y[48:]\n",
    "print(Y_val)\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = criterion(outputs.view(-1), Y_train.float())  # BCELoss expects float inputs\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    # if loss.item() < best_val_loss and epoch % 2000 == 0:\n",
    "    #     best_val_loss = loss.item()\n",
    "    #     torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        accuracy, sensitivity, specificity = val(model, X_train, Y_train)\n",
    "        val_accuracy, val_sensitivity,val_specificity = val(model, X_val, Y_val)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}', ' train acc, sen, spec: ',accuracy, sensitivity, specificity, ' val acc, sen, spec: ',val_accuracy, val_sensitivity,val_specificity )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "loaded_model = LogisticRegression(input_size)\n",
    "loaded_model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "patient_id_list1 = patient_id_list[idx]\n",
    "\n",
    "def val(loaded_model, X, Y):\n",
    "    y_pred = []\n",
    "    y_pred_float = []\n",
    "\n",
    "    for index in range(0,X.shape[0]):\n",
    "        new_data = X[index,:]\n",
    "\n",
    "        # Put the model in evaluation mode\n",
    "        loaded_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = loaded_model(new_data)\n",
    "            y_pred_float.append(prediction.item())\n",
    "            predicted_class = 1 if prediction.item() > 0.5 else 0\n",
    "            y_pred.append(predicted_class)\n",
    "            # print('patient id: ',patient_id_list1[index]  , f'Predicted class: {predicted_class}, Probability: {prediction.item()}', ' ground truth: ', Y[index], 'correct?: ', predicted_class == Y[index])\n",
    "\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    y_pred_float = np.asarray(y_pred_float)\n",
    "    y_true = torch.clone(Y).numpy()\n",
    "\n",
    "    # calculate accuracy using predict_collect and ground truth\n",
    "    accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
    "    # print('accuracy: ', accuracy)\n",
    "    # also calculate sensitivity and specificity, write the code please\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    # print('true positive: ', TP, 'true negative: ', TN, 'false positive: ', FP, 'false negative: ', FN)\n",
    "\n",
    "    # Sensitivity (True Positive Rate)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "\n",
    "    # Specificity (True Negative Rate)\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "    # print('sensitivity: ', sensitivity, 'specificity: ', specificity)\n",
    "\n",
    "    # # use y_pred_float and y_true to calculate AUC\n",
    "    # from sklearn.metrics import roc_auc_score\n",
    "    # auc = roc_auc_score(y_true, y_pred_float)\n",
    "    # # print(auc)\n",
    "    return accuracy, sensitivity, specificity\n",
    "\n",
    "accuracy, sensitivity, specificity = val(loaded_model, X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import DeepStrain.functions_collection as ff\n",
    "\n",
    "main_path = '/mnt/mount_zc_NAS/Deepstrain'\n",
    "data_path = '/mnt/mount_zc_NAS/HFpEF/data/HFpEF_data'\n",
    "spreadsheet = pd.read_excel(os.path.join(data_path, 'Patient_list', 'Important_HFpEF_Patient_list_unique_patient_w_readmission_finalized.xlsx' ))\n",
    "\n",
    "patient_list = spreadsheet.iloc[0:50]\n",
    "patient_id_list = patient_list['OurID']\n",
    "patient_id_list = torch.from_numpy(patient_id_list.to_numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for patient_index in range(0,patient_list.shape[0]):\n",
    "    patient_id_num = patient_list['OurID'].iloc[patient_index]\n",
    "    patient_id = ff.XX_to_ID_00XX(patient_id_num)\n",
    "\n",
    "    # load strain first:\n",
    "    strain_folder = os.path.join(main_path, 'results/strain', patient_id)\n",
    "    # global strain\n",
    "    global_strain = np.load(os.path.join(strain_folder, 'global_strain.npy'))\n",
    "    global_radial_strain = np.asarray(global_strain[0]).reshape(1,-1)\n",
    "    global_circumferential_strain = np.asarray(global_strain[1]).reshape(1,-1)\n",
    "\n",
    "    # layer strain\n",
    "    layer_strain = np.load(os.path.join(strain_folder, 'layer_strain.npy'))\n",
    "    layer_radial_strain = layer_strain[0,:].reshape(1,-1)\n",
    "    layer_circumferential_strain = layer_strain[1,:].reshape(1,-1)\n",
    "\n",
    "    # polar strain\n",
    "    polar_strain = np.load(os.path.join(strain_folder, 'polar_strain.npy'), allow_pickle=True)\n",
    "    Ecc_aha = np.asarray(polar_strain[5][:-1]).reshape(1,-1)\n",
    "    Err_aha = np.asarray(polar_strain[7][:-1]).reshape(1,-1)\n",
    "\n",
    "    # WTCI\n",
    "    wtci = np.load(os.path.join(strain_folder, 'wtci.npy'), allow_pickle=True)\n",
    "    wtci_aha = np.asarray(wtci[4][:-1]).reshape(1,-1)\n",
    "\n",
    "    # load geometry then:\n",
    "    geometry_folder = os.path.join(main_path, 'results/geometry', patient_id)\n",
    "    # circular index\n",
    "    circular_index = np.load(os.path.join(geometry_folder, 'circular_index_collect.npy')).reshape(1,-1)\n",
    "    # centers\n",
    "    centers = np.load(os.path.join(geometry_folder, 'centers_collect.npy'), allow_pickle=True)\n",
    "    center_delta_to_base = centers[1][1:,:].reshape(1,-1)\n",
    "    enclosed_area = np.asarray(centers[-1]).reshape(1,-1)\n",
    "\n",
    "    # axis len\n",
    "    axis = np.load(os.path.join(geometry_folder, 'axis_len_collect.npy'), allow_pickle=True)\n",
    "    major_axis = axis[:-1,0].reshape(1,-1)\n",
    "    minor_axis = axis[:-1,1].reshape(1,-1)\n",
    "\n",
    "    # concatenate all features\n",
    "    features = np.concatenate((#global_radial_strain, global_circumferential_strain, \n",
    "                            layer_radial_strain, layer_circumferential_strain, \n",
    "                            Ecc_aha, np.concatenate((Err_aha[:,0:12] , wtci_aha[:,12:16]),axis = 1),\n",
    "                            # circular_index,\n",
    "                            major_axis,minor_axis),\n",
    "                            axis=1)\n",
    "    X.append(features)\n",
    "X = np.squeeze(np.asarray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 58]) (50,)\n"
     ]
    }
   ],
   "source": [
    "# Load Y\n",
    "Y = spreadsheet['label_for_ML'].iloc[0:50]\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "print(X.shape, Y.shape)\n",
    "Y = torch.from_numpy(Y.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
