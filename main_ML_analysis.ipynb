{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ema_pytorch import EMA\n",
    "from accelerate import Accelerator\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.ndimage import zoom\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import ast\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import nibabel as nb\n",
    "import matplotlib.pyplot as plt\n",
    "import functions_collection as ff\n",
    "import Data_processing as dp\n",
    "\n",
    "main_path = '/mnt/camca_NAS/Deepstrain/results'\n",
    "patinet_info = pd.read_excel('/mnt/camca_NAS/SAM_for_CMR/data/Patient_list/HFpEF_fulldataset_basic_info_edited.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_even_split(num_patients, label0_indices, label1_indices, num_groups=5):\n",
    "    # Shuffle the indices for random distribution\n",
    "    np.random.shuffle(label0_indices)\n",
    "    np.random.shuffle(label1_indices)\n",
    "    \n",
    "    # Initialize empty groups\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    \n",
    "    # Distribute label 1 patients across groups evenly\n",
    "    for i, idx in enumerate(label1_indices):\n",
    "        groups[i % num_groups].append(idx)\n",
    "    \n",
    "    # Distribute label 0 patients across groups evenly\n",
    "    for i, idx in enumerate(label0_indices):\n",
    "        groups[i % num_groups].append(idx)\n",
    "    \n",
    "    # Balance total patient count in each group by redistributing if needed\n",
    "    group_sizes = [len(group) for group in groups]\n",
    "    while max(group_sizes) - min(group_sizes) > 1:\n",
    "        # Find the group with the most patients and the group with the fewest\n",
    "        max_group = group_sizes.index(max(group_sizes))\n",
    "        min_group = group_sizes.index(min(group_sizes))\n",
    "        \n",
    "        # Move a patient from the largest group to the smallest group\n",
    "        patient_to_move = groups[max_group].pop()\n",
    "        groups[min_group].append(patient_to_move)\n",
    "        \n",
    "        # Recalculate group sizes\n",
    "        group_sizes = [len(group) for group in groups]\n",
    "\n",
    "    # print out each group composition\n",
    "    for j in range(5):\n",
    "        print('group ', j, 'sizes how many label 1 and label 0 ', len(groups[j]), len([i for i in groups[j] if i in label1_indices]), len([i for i in groups[j] if i in label0_indices]))\n",
    "        if j == 0:\n",
    "            print(' in this group the label 1 index is ', [i for i in groups[j] if i in label1_indices])\n",
    "    \n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the labels in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_0: 94\n",
      "count_1_no_surgery: 30\n",
      "count_1_surgery_no_readmission: 5\n",
      "count_1_surgery_readmission: 7\n",
      "count_1_readmission_in_one_year: 30\n",
      "count_1_readmission_larger_than_one_year: 12\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "label_sheet = pd.read_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_list_finalized.xlsx')\n",
    "label_list = []\n",
    "# counts\n",
    "count_0 = 0\n",
    "count_1_no_surgery = 0\n",
    "count_1_surgery_no_readmission = 0\n",
    "count_1_surgery_readmission = 0\n",
    "count_1_readmission_in_one_year = 0\n",
    "count_1_readmission_larger_than_one_year = 0\n",
    "\n",
    "results = []\n",
    "for i in range(0, label_sheet.shape[0]):\n",
    "    OurID = label_sheet.iloc[i, 0]\n",
    "    label = label_sheet.iloc[i, 1]\n",
    "\n",
    "    if '0.5' in str(label):\n",
    "        l = int(label[0])\n",
    "        initial_l = l\n",
    "    else:\n",
    "        l = int(label)\n",
    "        initial_l = l\n",
    "    \n",
    "    # readmission larger than one year\n",
    "    if l == 1:\n",
    "        readmission_date = int(label_sheet.iloc[i, 3])\n",
    "        study_date = int(label_sheet.iloc[i]['StudyDate'])\n",
    "       \n",
    "        readmission_date = datetime.strptime(str(readmission_date), \"%Y%m%d\")\n",
    "        study_date = datetime.strptime(str(study_date), \"%Y%m%d\")\n",
    "\n",
    "        # calculate the time difference\n",
    "        time_diff = (readmission_date - study_date).days\n",
    "        if time_diff >= 366:\n",
    "            l = 1\n",
    "    \n",
    "    # consider surgery also as readmission\n",
    "    if l == 0:\n",
    "        surgery = label_sheet.iloc[i, 4]\n",
    "        if surgery == 1:\n",
    "            l = 1\n",
    "    \n",
    "    # count\n",
    "    if l == 0:\n",
    "        count_0 += 1\n",
    "        no_surgery, surgery_and_no_readmission, surgery_and_readmission, time_diff = np.nan, np.nan, np.nan, np.nan\n",
    "    if l == 1:\n",
    "        if time_diff < 366:\n",
    "            count_1_readmission_in_one_year += 1\n",
    "        else:\n",
    "            count_1_readmission_larger_than_one_year += 1\n",
    "\n",
    "        surgery = label_sheet.iloc[i, 4]\n",
    "        if surgery == 0:\n",
    "            count_1_no_surgery += 1\n",
    "            no_surgery, surgery_and_no_readmission, surgery_and_readmission = 1, np.nan, np.nan\n",
    "        if surgery == 1:\n",
    "            if initial_l == 1:\n",
    "                count_1_surgery_readmission += 1\n",
    "                no_surgery, surgery_and_no_readmission, surgery_and_readmission = np.nan, np.nan, 1\n",
    "            else:\n",
    "                count_1_surgery_no_readmission += 1\n",
    "                no_surgery, surgery_and_no_readmission, surgery_and_readmission,time_diff = np.nan, 1, np.nan, np.nan\n",
    "\n",
    "    label_list.append(l)\n",
    "    results.append([OurID, l, initial_l, label, no_surgery, surgery_and_no_readmission, surgery_and_readmission, time_diff])\n",
    "label_list = np.asarray(label_list)\n",
    "df = pd.DataFrame(results, columns=['OurID', 'final_label', 'processed_label', 'expert_label', 'no_surgery', 'surgery_but_no_readmission', 'surgery_and_readmission', 'time_diff'])\n",
    "df.to_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_labels.xlsx', index=False)\n",
    "\n",
    "print('count_0:', count_0)\n",
    "print('count_1_no_surgery:', count_1_no_surgery)\n",
    "print('count_1_surgery_no_readmission:', count_1_surgery_no_readmission)\n",
    "print('count_1_surgery_readmission:', count_1_surgery_readmission)\n",
    "print('count_1_readmission_in_one_year:', count_1_readmission_in_one_year)\n",
    "print('count_1_readmission_larger_than_one_year:', count_1_readmission_larger_than_one_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the temporal strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 25-time-frame strain and get correlation matrix\n",
    "def correlation_matrix_cal(patient_id):\n",
    "\n",
    "    folders = ff.sort_timeframe(ff.find_all_target_files(['tf_*'],os.path.join(main_path,'strain',patient_id)), 0,'_','')\n",
    "    Ecc_aha_ori = np.zeros((len(folders),16))\n",
    "    Err_aha_ori = np.zeros((len(folders),16))\n",
    "    for i in range(len(folders)):\n",
    "        strain_file = np.load(os.path.join(main_path,'strain',patient_id,folders[i],'strain_info.npy'),allow_pickle=True)\n",
    "        ecc_aha = np.asarray(strain_file[-2][:-1] )\n",
    "        err_aha = np.asarray(strain_file[-1][:-1] )\n",
    "        Ecc_aha_ori[i] = ecc_aha\n",
    "        Err_aha_ori[i] = err_aha\n",
    "\n",
    "    Ecc_aha = np.zeros((16, len(folders))); Err_aha = np.zeros((16, len(folders)))\n",
    "    for i in range(0,16):\n",
    "        for j in range(len(folders)):\n",
    "            Ecc_aha[i,j] = Ecc_aha_ori[j,i]\n",
    "            Err_aha[i,j] = Err_aha_ori[j,i]\n",
    "\n",
    "    # sample 25 time frames\n",
    "    row_in_info = patinet_info[patinet_info['patient_id'] == patient_id]\n",
    "    t_original = ast.literal_eval(row_in_info['processed_time_frame_index_list'].values[0])\n",
    "    t_original = [int(i) for i in t_original]; t_original = np.asarray(t_original)\n",
    "    if t_original[0] !=0:\n",
    "        tt = []\n",
    "        for j in range(0, len(t_original)):\n",
    "            a = t_original[j] - t_original[0]\n",
    "            if a < 0:\n",
    "                a = t_original[j] - t_original[0] + 25\n",
    "            tt.append(a)\n",
    "        t_original = np.asarray(tt)\n",
    "            \n",
    "    t_new = np.arange(0, 25)\n",
    "\n",
    "    Ecc_aha_sample = np.zeros((16,25))\n",
    "    Err_aha_sample = np.zeros((16,25))\n",
    "    print(t_original, Ecc_aha.shape)\n",
    "\n",
    "    for i in range(16):\n",
    "        spl_ecc = make_interp_spline(t_original, Ecc_aha[i,:], k=2)  # k=3表示三次样条\n",
    "        ecc_new = spl_ecc(t_new)\n",
    "\n",
    "        spl_err = make_interp_spline(t_original, Err_aha[i,:], k=2)  # k=3表示三次样条\n",
    "        err_new = spl_err(t_new)\n",
    "\n",
    "        Ecc_aha_sample[i] = ecc_new\n",
    "        Err_aha_sample[i] = err_new\n",
    "\n",
    "    correlation_matrix_Ecc = np.corrcoef(Err_aha_sample)\n",
    "    correlation_matrix_Err = np.corrcoef(Ecc_aha_sample)\n",
    "    return correlation_matrix_Ecc, correlation_matrix_Err, Ecc_aha_sample, Err_aha_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it for each patient\n",
    "label_sheet = pd.read_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_list_finalized.xlsx')\n",
    "# for i in range(0, label_sheet.shape[0]):\n",
    "#     patient_id = ff.XX_to_ID_00XX(label_sheet.iloc[i, 0])\n",
    "    \n",
    "#     print(i, patient_id)\n",
    "        \n",
    "#     correlation_matrix_Ecc, correlation_matrix_Err, Ecc_aha_sample, Err_aha_sample = correlation_matrix_cal(patient_id)\n",
    "#     # np.save(os.path.join(main_path, 'strain', patient_id, 'correlation_matrix_Ecc.npy'), correlation_matrix_Ecc)\n",
    "#     # np.save(os.path.join(main_path, 'strain', patient_id, 'correlation_matrix_Err.npy'), correlation_matrix_Err)\n",
    "#     np.save(os.path.join(main_path, 'strain', patient_id, 'Ecc_aha_sample.npy'), Ecc_aha_sample)\n",
    "#     np.save(os.path.join(main_path, 'strain', patient_id, 'Err_aha_sample.npy'), Err_aha_sample)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the strain results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize strain\n",
    "label_sheet = pd.read_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_list_finalized.xlsx')\n",
    "for k in range(0,label_sheet.shape[0]):\n",
    "    patient_id = ff.XX_to_ID_00XX(label_sheet.iloc[k, 0])\n",
    "    print(patient_id)\n",
    "\n",
    "    Ecc_aha_sample = np.load(os.path.join(main_path, 'strain', patient_id, 'Ecc_aha_sample.npy'))\n",
    "    Err_aha_sample = np.load(os.path.join(main_path, 'strain', patient_id, 'Err_aha_sample.npy'))\n",
    "    correlation_matrix_Ecc = np.corrcoef(Err_aha_sample)\n",
    "    correlation_matrix_Err = np.corrcoef(Ecc_aha_sample)\n",
    "\n",
    "    data_list = [Ecc_aha_sample, Err_aha_sample]\n",
    "    for ii in range(0,2):\n",
    "        data = data_list[ii]\n",
    "        name = 'Ecc' if ii == 0 else 'Err'\n",
    "\n",
    "        # Define the segment names for the AHA 16 segments\n",
    "        segment_names = [\n",
    "            'Basal Anterior','Basal Anteroseptal','Basal Inferoseptal','Basal Inferior','Basal Inferolateral','Basal Anterolateral',\n",
    "            'Mid Anterior','Mid Anteroseptal','Mid Inferoseptal','Mid Inferior','Mid Inferolateral','Mid Anterolateral',\n",
    "            'Apical Anterior','Apical Septal','Apical Inferior','Apical Lateral']\n",
    "\n",
    "        # Time points from 0 to 15 (total 16 points, but since your data has 15 observations, use 0 to 14)\n",
    "        time_points = np.arange(25)\n",
    "\n",
    "        # find the max and min value in data\n",
    "        max_value = np.max(data)\n",
    "        min_value = np.min(data)\n",
    "        # print('max_value:', max_value, 'min_value:', min_value)\n",
    "        # ytick_values = np.arange(np.round(min_value - 0.1,1), np.round(max_value + 0.2,1), 0.1)\n",
    "        ytick_values = np.arange(-0.40,0.11,0.1) if ii == 0 else np.arange(-0.10,0.51,0.1)\n",
    "        \n",
    "        # Create a 4x4 grid of plots\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(10,10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i in range(16):\n",
    "            axes[i].plot(time_points, data[i, :], marker='o', markersize = 3)\n",
    "            axes[i].set_title(segment_names[i])\n",
    "            axes[i].set_xlabel('Time')\n",
    "            axes[i].set_ylabel(name)\n",
    "            axes[i].grid(True)\n",
    "            axes[i].set_ylim(np.min(ytick_values), np.max(ytick_values))\n",
    "            # axes[i].set_ylim(-0.10,0.50)\n",
    "            axes[i].set_yticks(ytick_values)\n",
    "            axes[i].set_xticks(time_points,fontsize=1)\n",
    "            axes[i].set_xticklabels(time_points, fontsize=6)\n",
    "            \n",
    "\n",
    "        # Adjust layout to prevent overlap\n",
    "        plt.tight_layout()\n",
    "        # save\n",
    "        plt.savefig(os.path.join(main_path, 'strain', patient_id, name+'.png'))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize correlation\n",
    "# first we need to know the range of correlation matrix\n",
    "\n",
    "label_sheet = pd.read_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_list_finalized.xlsx')\n",
    "correlation_Ecc_min_list = []\n",
    "correlation_Err_min_list = []\n",
    "for k in range(0,label_sheet.shape[0]):\n",
    "    patient_id = ff.XX_to_ID_00XX(label_sheet.iloc[k, 0])\n",
    "\n",
    "    Ecc_aha_sample = np.load(os.path.join(main_path, 'strain', patient_id, 'Ecc_aha_sample.npy'))\n",
    "    Err_aha_sample = np.load(os.path.join(main_path, 'strain', patient_id, 'Err_aha_sample.npy'))\n",
    "    correlation_matrix_Ecc = np.corrcoef(Ecc_aha_sample)\n",
    "    correlation_matrix_Err = np.corrcoef(Err_aha_sample)\n",
    "    correlation_Ecc_min = np.min(correlation_matrix_Ecc); correlation_Ecc_min_list.append(correlation_Ecc_min)\n",
    "    correlation_Err_min = np.min(correlation_matrix_Err); correlation_Err_min_list.append(correlation_Err_min)\n",
    "\n",
    "    # print('patient_id:', patient_id, ' correlation_Ecc_min:', correlation_Ecc_min, ' correlation_Err_min:', correlation_Err_min)\n",
    "print('the min for all dataset: correlation_Ecc_min:', np.min(correlation_Ecc_min_list), ' correlation_Err_min:', np.min(correlation_Err_min_list))\n",
    "\n",
    "# then plot \n",
    "for k in range(0,label_sheet.shape[0]):\n",
    "    patient_id = ff.XX_to_ID_00XX(label_sheet.iloc[k, 0])\n",
    "    print(patient_id)\n",
    "\n",
    "    Ecc_aha_sample = np.load(os.path.join(main_path, 'strain', patient_id, 'Ecc_aha_sample.npy'))\n",
    "    Err_aha_sample = np.load(os.path.join(main_path, 'strain', patient_id, 'Err_aha_sample.npy'))\n",
    "    correlation_matrix_Ecc = np.corrcoef(Ecc_aha_sample)\n",
    "    correlation_matrix_Err = np.corrcoef(Err_aha_sample)\n",
    "\n",
    "    correlation_list = [correlation_matrix_Ecc, correlation_matrix_Err]\n",
    "\n",
    "    for ii in range(0,2):\n",
    "        correlation_matrix = correlation_list[ii]\n",
    "        name = 'Ecc' if ii == 0 else 'Err'\n",
    "\n",
    "        vmin = -0.2 if ii == 0 else -1.0\n",
    "        vmax = 1.0\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        img = plt.imshow(correlation_matrix, cmap='hot', interpolation='nearest', vmin = vmin, vmax = vmax)  # Fix color range\n",
    "        cbar = plt.colorbar(img)\n",
    "        cbar.set_label('Correlation Coefficient')\n",
    "        \n",
    "        # Title and axis labels\n",
    "        plt.title('Correlation Matrix_'+name)\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Sample Index')\n",
    "\n",
    "        # Set x and y ticks\n",
    "        plt.xticks(range(16));plt.yticks(range(16))\n",
    "        plt.savefig(os.path.join(main_path, 'strain', patient_id, 'correlation_matrix_'+name+'.png'))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate simple GLS first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 8)\n"
     ]
    }
   ],
   "source": [
    "# load labels\n",
    "label_sheet = pd.read_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_labels.xlsx')\n",
    "label_sheet = label_sheet.fillna(0)\n",
    "# exclude the patients with immediate surgery but no re-admission\n",
    "label_sheet = label_sheet[label_sheet['surgery_but_no_readmission'] != 1]\n",
    "print(label_sheet.shape)\n",
    "label_list = label_sheet['final_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLS\n",
    "gls_list = []\n",
    "for i in range(0, label_sheet.shape[0]):\n",
    "    patient_id = ff.XX_to_ID_00XX(label_sheet.iloc[i, 0])\n",
    "    file = os.path.join(main_path, 'strain', patient_id, 'gls.npy')\n",
    "    f = np.load(file)\n",
    "    gls = f[-1]\n",
    "    gls_list.append(gls)\n",
    "gls_list = np.asarray(gls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 94  label 1: 42\n",
      "0.4063931209448106 0.6851020716835795\n"
     ]
    }
   ],
   "source": [
    "label_0_group = np.where(label_list == 0)[0]\n",
    "label_1_group = np.where(label_list == 1)[0]\n",
    "print('label 0:', len(label_0_group), ' label 1:', len(label_1_group))\n",
    "\n",
    "gls_0 = gls_list[label_0_group]\n",
    "gls_1 = gls_list[label_1_group]\n",
    "\n",
    "# found out whether gls_0 is significantly different from gls_1\n",
    "from scipy.stats import ttest_ind\n",
    "t, p = ttest_ind(gls_0, gls_1)\n",
    "print(t, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gls_0_mean: -0.262000980569946  gls_1_mean: -0.2680157313250636\n"
     ]
    }
   ],
   "source": [
    "gls_0_mean = np.mean(gls_0)\n",
    "gls_1_mean = np.mean(gls_1)\n",
    "print('gls_0_mean:', gls_0_mean, ' gls_1_mean:', gls_1_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for the ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label0_indices: 94  label1_indices: 42\n",
      "[30, 102, 67, 12, 44, 29, 58, 123, 18, 126, 116, 99, 42, 83, 15, 37, 103, 39, 20, 91, 6, 97, 52, 75, 107, 35, 11]\n"
     ]
    }
   ],
   "source": [
    "# label\n",
    "label_sheet = pd.read_excel('/mnt/camca_NAS/HFpEF/data/HFpEF_data/Patient_list/re-admission-info/HFpEF_readmission_labels.xlsx')\n",
    "label_sheet = label_sheet.fillna(0)\n",
    "\n",
    "# find the indexes with label 0 and label 1\n",
    "label0_indices = list(label_sheet[label_sheet['final_label'] == 0].index)\n",
    "label1_indices = list(label_sheet[label_sheet['final_label'] == 1].index)\n",
    "print('label0_indices:', len(label0_indices), ' label1_indices:', len(label1_indices))\n",
    "\n",
    "save_file = os.path.join(os.path.dirname(main_path), 'HFpEF_analysis', 'data_split', 'groups_all_data.npy')\n",
    "\n",
    "if os.path.isfile(save_file):\n",
    "    groups = np.load(save_file, allow_pickle=True)\n",
    "else:\n",
    "    # Get the split groups\n",
    "    groups = stratified_even_split(label_sheet.shape[0], label0_indices, label1_indices)\n",
    "\n",
    "    # save the groups\n",
    "    np.save(save_file, groups)\n",
    "print(groups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Ecc, Err, Ecc_matrix, Err_matrix: (16, 13) (12, 13) (16, 16) (12, 12)\n"
     ]
    }
   ],
   "source": [
    "##### Load data: X\n",
    "X_Ecc = []\n",
    "X_Err = []\n",
    "X_Ecc_corr = []\n",
    "X_Err_corr = []\n",
    "\n",
    "for i in range(0, label_sheet.shape[0]):\n",
    "    patient_id = ff.XX_to_ID_00XX(label_sheet.iloc[i, 0])\n",
    "    # print(patient_id)\n",
    "    correlation_matrix_Ecc = np.load(os.path.join(main_path, 'strain', patient_id, 'correlation_matrix_Ecc.npy'))\n",
    "    correlation_matrix_Err = np.load(os.path.join(main_path, 'strain', patient_id, 'correlation_matrix_Err.npy'))\n",
    "    Ecc_aha = np.load(os.path.join(main_path, 'strain', patient_id, 'Ecc_aha_sample.npy'))\n",
    "    Err_aha = np.load(os.path.join(main_path, 'strain', patient_id, 'Err_aha_sample.npy'))\n",
    "\n",
    "    # we don't use Err apical:\n",
    "    Err_aha = Err_aha[0:12,:]\n",
    "    correlation_matrix_Err = np.corrcoef(Err_aha)\n",
    "    \n",
    "    # for Ecc and Err, for each aha segment (row), we only sample half of the data\n",
    "    Ecc_aha_sample = Ecc_aha[:,np.arange(0,25,2)]\n",
    "    Err_aha_sample = Err_aha[:,np.arange(0,25,2)]\n",
    "    \n",
    "    if i == 0:\n",
    "        print('shape of Ecc, Err, Ecc_matrix, Err_matrix:', Ecc_aha_sample.shape, Err_aha_sample.shape, correlation_matrix_Ecc.shape, correlation_matrix_Err.shape)\n",
    "\n",
    "    # flat each variable and add to the list\n",
    "    X_Ecc.append(Ecc_aha_sample.flatten())\n",
    "    X_Err.append(Err_aha_sample.flatten())\n",
    "    X_Ecc_corr.append(correlation_matrix_Ecc.flatten())\n",
    "    X_Err_corr.append(correlation_matrix_Err.flatten())\n",
    "\n",
    "# load data Y\n",
    "Y = label_sheet['final_label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "class XGBoostClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, save_folder, num_classes, n_estimators=100, learning_rate=1e-3, max_depth=3, use_gpu=True):\n",
    "        super(XGBoostClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.save_folder = save_folder\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        # Initialize an XGBoost model\n",
    "        self.xgb_model = xgb.XGBClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=self.learning_rate,\n",
    "            max_depth=self.max_depth,\n",
    "            objective='multi:softprob',\n",
    "            num_class=self.num_classes,\n",
    "            # use_label_encoder=False,\n",
    "            eval_metric='mlogloss',\n",
    "            tree_method=\"hist\",   \n",
    "            device=\"cuda\" if self.use_gpu else \"cpu\"  ,\n",
    "            # predictor='gpu_predictor' if self.use_gpu else 'auto',\n",
    "            verbosity = 1,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        pred_prob = self.xgb_model.predict_proba(x_np)\n",
    "        pred_prob_tensor = torch.tensor(pred_prob, dtype=torch.float32, device=x.device)\n",
    "        return pred_prob_tensor\n",
    "\n",
    "    def fit(self, val_batch_index, x_train, y_train, x_val=None, y_val=None):\n",
    "        x_train_np = x_train.detach().cpu().numpy()\n",
    "        y_train_np = y_train.detach().cpu().numpy()\n",
    "        \n",
    "        if x_val is not None and y_val is not None:\n",
    "            x_val_np = x_val.detach().cpu().numpy()\n",
    "            y_val_np = y_val.detach().cpu().numpy()\n",
    "        \n",
    "        training_log = []\n",
    "        for epoch in range(self.n_estimators):\n",
    "            self.xgb_model.n_estimators = epoch + 1\n",
    "            self.xgb_model.fit(x_train_np, y_train_np, eval_set=[(x_val_np, y_val_np)] if x_val is not None else None, verbose=False)\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            train_preds = self.xgb_model.predict(x_train_np)\n",
    "            train_preds = np.argmax(train_preds, axis=1)\n",
    "            train_acc = accuracy_score(y_train_np, train_preds)\n",
    "\n",
    "            # Calculate training sensitivity and specificity\n",
    "            train_cm = confusion_matrix(y_train_np, train_preds)\n",
    "            train_sensitivity = train_cm[1, 1] / (train_cm[1, 1] + train_cm[1, 0])  # TP / (TP + FN)\n",
    "            train_specificity = train_cm[0, 0] / (train_cm[0, 0] + train_cm[0, 1])  # TN / (TN + FP)\n",
    "            \n",
    "            # Print training accuracy\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.n_estimators}\")\n",
    "                print(f\"Training Accuracy: {train_acc:.4f}\", \"sensitivity: \", train_sensitivity, \"specificity: \", train_specificity)\n",
    "                \n",
    "                if x_val is not None:\n",
    "                    # Calculate validation accuracy\n",
    "                    val_preds = self.xgb_model.predict(x_val_np)\n",
    "                    val_preds = np.argmax(val_preds, axis=1)\n",
    "                    val_acc = accuracy_score(y_val_np, val_preds)\n",
    "\n",
    "                    val_cm = confusion_matrix(y_val_np, val_preds)\n",
    "                    val_sensitivity = val_cm[1, 1] / (val_cm[1, 1] + val_cm[1, 0])  # TP / (TP + FN)\n",
    "                    val_specificity = val_cm[0, 0] / (val_cm[0, 0] + val_cm[0, 1])  # TN / (TN + FP)\n",
    "                    \n",
    "                    # Print validation accuracy\n",
    "                    print(f\"Validation Accuracy: {val_acc:.4f}\", \"sensitivity: \", val_sensitivity, \"specificity: \", val_specificity)\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "                # save the training log\n",
    "                training_log.append([epoch, train_acc, train_sensitivity, train_specificity, val_acc, val_sensitivity, val_specificity])\n",
    "                df = pd.DataFrame(training_log,columns = ['iteration', 'train_accuracy', 'train_sensitivity', 'train_specificity', 'val_accuracy', 'val_sensitivity', 'val_specificity'])\n",
    "                log_folder = os.path.join(self.save_folder,'log');ff.make_folder([log_folder])\n",
    "                df.to_excel(os.path.join(log_folder, 'training_log_val' + str(val_batch_index) +'.xlsx'),index=False)\n",
    "                ff.make_folder([os.path.join(self.save_folder, 'models')])\n",
    "                self.xgb_model.save_model(os.path.join(self.save_folder, 'models', 'model_val' + str(val_batch_index) + '_epoch' + str(epoch) + '.json'))\n",
    "\n",
    "    def load(self, model_path):\n",
    "        self.xgb_model.load_model(model_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        preds = self.xgb_model.predict(x_np)\n",
    "        preds_tensor = torch.tensor(preds, dtype=torch.long, device=x.device)\n",
    "        return preds_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 109  val: 27\n",
      "X_train.shape: (109, 364)  X_val.shape: (27, 364)  Y_train.shape: (109,)  Y_val.shape: (27,)\n",
      "Epoch 1/10000\n",
      "Training Accuracy: 0.9450 sensitivity:  0.8181818181818182 specificity:  1.0\n",
      "Validation Accuracy: 0.5926 sensitivity:  0.1111111111111111 specificity:  0.8333333333333334\n",
      "------------------------------\n",
      "Epoch 101/10000\n",
      "Training Accuracy: 0.9450 sensitivity:  0.8181818181818182 specificity:  1.0\n",
      "Validation Accuracy: 0.5556 sensitivity:  0.1111111111111111 specificity:  0.7777777777777778\n",
      "------------------------------\n",
      "Epoch 201/10000\n",
      "Training Accuracy: 0.9450 sensitivity:  0.8181818181818182 specificity:  1.0\n",
      "Validation Accuracy: 0.5556 sensitivity:  0.1111111111111111 specificity:  0.7777777777777778\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "## main\n",
    "# define train and val\n",
    "for k in range(0,5):\n",
    "    g = groups.copy()\n",
    "    val = g[k]\n",
    "    train_g = list(np.delete(g,k))\n",
    "    train = list(chain.from_iterable(train_g))\n",
    "    # make train randomly shuffle\n",
    "    random.shuffle(train)\n",
    "    print('train:', len(train), ' val:', len(val))\n",
    "    X_train_Ecc = [X_Ecc[i] for i in train]; X_val_Ecc = [X_Ecc[i] for i in val]\n",
    "    X_train_Err = [X_Err[i] for i in train]; X_val_Err = [X_Err[i] for i in val]\n",
    "    X_train_Ecc_corr = [X_Ecc_corr[i] for i in train]; X_val_Ecc_corr = [X_Ecc_corr[i] for i in val]\n",
    "    X_train_Err_corr = [X_Err_corr[i] for i in train]; X_val_Err_corr = [X_Err_corr[i] for i in val]\n",
    "    Y_train = Y[train]; Y_val = Y[val]\n",
    "    \n",
    "\n",
    "    # pick which data is going to be input\n",
    "    X_train = np.asarray([np.asarray(list(X_train_Ecc[i]) + list(X_train_Err[i])) for i in range(0,len(X_train_Ecc))])\n",
    "    X_val = np.asarray([np.asarray(list(X_val_Ecc[i]) + list(X_val_Err[i])) for i in range(0,len(X_val_Ecc))])\n",
    "    print('X_train.shape:', X_train.shape, ' X_val.shape:', X_val.shape, ' Y_train.shape:', Y_train.shape, ' Y_val.shape:', Y_val.shape)\n",
    "\n",
    "    save_folder = os.path.join('/mnt/camca_NAS/Deepstrain/HFpEF_analysis/models/XGBoost_Ecc_Err/', 'val' + str(k))\n",
    "\n",
    "    # train\n",
    "    model = XGBoostClassifier(input_dim=X_train.shape[1], num_classes=2, use_gpu=torch.cuda.is_available(), save_folder=save_folder, n_estimators=10000)\n",
    "\n",
    "    # Train the model with training and validation data\n",
    "    model.fit(k, torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).long(), torch.from_numpy(X_val), torch.from_numpy(Y_val).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict main\n",
    "epoch_list = [480,80,40,400,400]\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "for i in range(0,5):\n",
    "    val_batch_index = i\n",
    "    GROUP = groups.copy()\n",
    "    val = GROUP.pop(val_batch_index)\n",
    "    X_val = X[val]; Y_val = Y[val]\n",
    "\n",
    "    epoch = epoch_list[i]\n",
    "    save_folder = os.path.join('/mnt/camca_NAS/Deepstrain/HFpEF_analysis/models/XGBoost_Ecc/', 'val' + str(val_batch_index))\n",
    "    model = XGBoostClassifier(input_dim=X_val.shape[1], num_classes=2, use_gpu=torch.cuda.is_available(), save_folder=save_folder, n_estimators=500)\n",
    "    model.load(os.path.join(save_folder, 'models', 'model_val' + str(val_batch_index) + '_epoch' + str(epoch) + '.json'))\n",
    "    y_preds = model.predict(torch.from_numpy(X_val).float())\n",
    "    y_preds = np.argmax(y_preds, axis=1)\n",
    "    y_pred_list.append(y_preds)\n",
    "    y_true_list.append(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6323529411764706  sensitivity: 0.21428571428571427  specificity: 0.8191489361702128\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = list(chain.from_iterable(y_pred_list)); y_pred_list = np.asarray(y_pred_list)\n",
    "y_true_list = list(chain.from_iterable(y_true_list)) ; y_true_list = np.asarray(y_true_list)\n",
    "accuracy, sensitivity, specificity,_,_,_,_ = ff.quantitative(y_pred_list, y_true_list)\n",
    "print('accuracy:', accuracy, ' sensitivity:', sensitivity, ' specificity:', specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,\n",
    "                  input_size, hidden_size = 128):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)  # Hidden layer\n",
    "        self.output = nn.Linear(hidden_size, 1)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))  # Sigmoid activation for hidden layer\n",
    "        out = torch.sigmoid(self.output(x))  # Sigmoid activation for output layer\n",
    "        return out\n",
    "\n",
    "class LogisticRegression_Trainer():\n",
    "    def __init__(\n",
    "        self,\n",
    "        regression_model,\n",
    "        train_num_steps,\n",
    "        save_folder,\n",
    "\n",
    "        train_lr = 1e-3,\n",
    "        train_lr_decay_every = 1,\n",
    "        save_models_every = 2,):\n",
    "        \n",
    "\n",
    "        super().__init__()\n",
    "        self.model = regression_model\n",
    "        self.input_size = regression_model.input_size\n",
    "        self.save_folder = save_folder; os.makedirs(self.save_folder, exist_ok=True)\n",
    "\n",
    "        # loss:\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        # optimizer\n",
    "        self.opt = Adam(self.model.parameters(), lr = train_lr, betas = (0.9, 0.99))\n",
    "        # self.opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "        self.scheduler = StepLR(self.opt, step_size = 1, gamma=0.95)\n",
    "        self.train_lr_decay_every = train_lr_decay_every\n",
    "        self.step = 0\n",
    "        self.train_num_steps = train_num_steps\n",
    "        self.save_models_every = save_models_every\n",
    "\n",
    "    def simple_val(self,trained_model, x, y):\n",
    "        y_pred = []; y_pred_float = []\n",
    "\n",
    "        for index in range(0,x.shape[0]):\n",
    "            new_data = x[index,:]\n",
    "\n",
    "            trained_model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = trained_model(new_data); y_pred_float.append(prediction.item())\n",
    "                predicted_class = 1 if prediction.item() > 0.5 else 0; y_pred.append(predicted_class)\n",
    "\n",
    "        y_pred = np.asarray(y_pred); y_pred_float = np.asarray(y_pred_float); y_true = torch.clone(y).numpy()\n",
    "\n",
    "        # calculate accuracy using predict_collect and ground truth\n",
    "        accuracy, sensitivity, specificity,_,_,_,_ = ff.quantitative(y_pred, y_true)\n",
    "        return y_pred, y_pred_float, accuracy, sensitivity, specificity\n",
    "\n",
    "    def save_model(self, stepNum):\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'model': self.model.state_dict(),\n",
    "            'opt': self.opt.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),}\n",
    "        os.makedirs(os.path.join(self.save_folder, 'models'), exist_ok=True)\n",
    "        torch.save(data, os.path.join(self.save_folder, 'models', 'model-' + str(stepNum) + '.pt'))\n",
    "\n",
    "    def load_model(self, trained_model_filename):\n",
    "        data = torch.load(trained_model_filename)\n",
    "\n",
    "        self.model.load_state_dict(data['model'])\n",
    "\n",
    "        self.step = data['step']\n",
    "        self.opt.load_state_dict(data['opt'])\n",
    "        self.scheduler.load_state_dict(data['scheduler'])\n",
    "\n",
    "\n",
    "    def train(self, X_train, Y_train, X_val, Y_val, pre_trained_model = None ,start_step = None):\n",
    "    \n",
    "        training_log = []\n",
    "\n",
    "        # load pre-trained\n",
    "        if pre_trained_model is not None:\n",
    "            self.load_model(pre_trained_model)\n",
    "            print('model loaded from ', pre_trained_model)\n",
    "\n",
    "        if start_step is not None:\n",
    "            self.step = start_step\n",
    "\n",
    "        with tqdm(initial = self.step, total = self.train_num_steps) as pbar:\n",
    "            \n",
    "            while self.step < self.train_num_steps:\n",
    "                # print('training epoch: ', self.step + 1)\n",
    "                # print('learning rate: ', self.scheduler.get_last_lr()[0])\n",
    "\n",
    "                self.opt.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(X_train)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.criterion(outputs.view(-1), Y_train.float())  # BCELoss expects float inputs\n",
    "\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "\n",
    "                self.step += 1\n",
    "\n",
    "                # save the model\n",
    "                if self.step !=0 and (self.step % self.save_models_every == 0):\n",
    "                   self.save_model(self.step)\n",
    "                \n",
    "                if self.step !=0 and (self.step % self.train_lr_decay_every == 0):\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                if self.step !=0 and (self.step % self.save_models_every == 0):\n",
    "                    _,_, train_accuracy, train_sensitivity, train_specificity = self.simple_val(self.model, X_train, Y_train)\n",
    "                    _,_, val_accuracy, val_sensitivity, val_specificity = self.simple_val(self.model, X_val, Y_val)\n",
    "                    print('epoch is: ', self.step, ' train loss: ', loss.item(), ' train accuracy: ', train_accuracy, ' sensitivity: ', train_sensitivity, ' specificity: ', train_specificity, ' val accuracy: ', val_accuracy, ' sensitivity: ', val_sensitivity, ' specificity: ', val_specificity) \n",
    "                            \n",
    "                    # save the training log\n",
    "                    training_log.append([self.step,self.scheduler.get_last_lr()[0], loss.item(), train_accuracy, train_sensitivity, train_specificity, val_accuracy, val_sensitivity, val_specificity])\n",
    "                    df = pd.DataFrame(training_log,columns = ['iteration','learning_rate', 'train_loss', 'train_accuracy', 'train_sensitivity', 'train_specificity', 'val_accuracy', 'val_sensitivity', 'val_specificity'])\n",
    "                    log_folder = os.path.join(self.save_folder,'log');ff.make_folder([log_folder])\n",
    "                    df.to_excel(os.path.join(log_folder, 'training_log.xlsx'),index=False)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # main\n",
    "# # define train and val\n",
    "# from itertools import chain\n",
    "# val_batch_index = 4\n",
    "# GROUP = groups.copy()\n",
    "# val = GROUP.pop(val_batch_index)\n",
    "# train = GROUP; train = list(chain.from_iterable(train))\n",
    "# print('train:', len(train), ' val:', len(val))\n",
    "# X_train = X[train]; Y_train = Y[train]\n",
    "# X_val = X[val]; Y_val = Y[val]\n",
    "# print('X_train shape:', X_train.shape, ' Y_train shape:', Y_train.shape, ' X_val shape:', X_val.shape, ' Y_val shape:', Y_val.shape)\n",
    "\n",
    "# save_folder = os.path.join('/mnt/camca_NAS/Deepstrain/HFpEF_analysis/models/LogisticRegression_Ecc_Err/', 'val' + str(val_batch_index))\n",
    "# ff.make_folder([save_folder])\n",
    "\n",
    "# model = LogisticRegression(input_size = X_train.shape[-1])\n",
    "# trainer = LogisticRegression_Trainer(model,  train_num_steps = 10000,\n",
    "#                   save_folder = save_folder,\n",
    "#                   train_lr = 1e-3,  train_lr_decay_every = 100,   save_models_every = 100,)\n",
    "\n",
    "# trainer.train(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).long(), torch.from_numpy(X_val).float(), torch.from_numpy(Y_val).long(), pre_trained_model = None ,start_step = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict main\n",
    "epoch_list = [900,5000,5000,5000,5000]\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "for i in range(0,5):\n",
    "    val_batch_index = i\n",
    "    GROUP = groups.copy()\n",
    "    val = GROUP.pop(val_batch_index)\n",
    "    X_val = X[val]; Y_val = Y[val]\n",
    "\n",
    "    epoch = epoch_list[i]\n",
    "    save_folder = os.path.join('/mnt/camca_NAS/Deepstrain/HFpEF_analysis/models/LogisticRegression_Strain/', 'val' + str(val_batch_index))\n",
    "    model = LogisticRegression(input_size = X_val.shape[-1])\n",
    "    trainer = LogisticRegression_Trainer(model,  train_num_steps = 10000,\n",
    "                  save_folder = save_folder,\n",
    "                  train_lr = 1e-3,  train_lr_decay_every = 100,   save_models_every = 100,)\n",
    "    trainer.load_model(os.path.join(save_folder, 'models', 'model-' + str(epoch) + '.pt'))\n",
    "\n",
    "    \n",
    "    y_pred,_,_,_,_ = trainer.simple_val(model, torch.from_numpy(X_val).float(), torch.from_numpy(Y_val).long())\n",
    "    y_pred_list.append(y_pred)\n",
    "    y_true_list.append(Y_val)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5882352941176471  sensitivity: 0.3333333333333333  specificity: 0.7021276595744681\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = list(chain.from_iterable(y_pred_list)); y_pred_list = np.asarray(y_pred_list)\n",
    "y_true_list = list(chain.from_iterable(y_true_list)) ; y_true_list = np.asarray(y_true_list)\n",
    "accuracy, sensitivity, specificity,_,_,_,_ = ff.quantitative(y_pred_list, y_true_list)\n",
    "print('accuracy:', accuracy, ' sensitivity:', sensitivity, ' specificity:', specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample 25 time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ecc_aha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Documents/DeepStrain/main_ML_analysis.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505536227d/workspace/Documents/DeepStrain/main_ML_analysis.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m Err_aha_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m16\u001b[39m,\u001b[39m25\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505536227d/workspace/Documents/DeepStrain/main_ML_analysis.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m16\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505536227d/workspace/Documents/DeepStrain/main_ML_analysis.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     spl_ecc \u001b[39m=\u001b[39m make_interp_spline(t_original, Ecc_aha[i,:], k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# k=3表示三次样条\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505536227d/workspace/Documents/DeepStrain/main_ML_analysis.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     ecc_new \u001b[39m=\u001b[39m spl_ecc(t_new)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505536227d/workspace/Documents/DeepStrain/main_ML_analysis.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     spl_err \u001b[39m=\u001b[39m make_interp_spline(t_original, Err_aha[i,:], k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# k=3表示三次样条\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ecc_aha' is not defined"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.interpolate import make_interp_spline\n",
    "# import ast\n",
    "\n",
    "# patient_id = 'ID_0692'\n",
    "\n",
    "# # sample 25 time frames\n",
    "# row_in_info = patinet_info[patinet_info['patient_id'] == patient_id]\n",
    "# t_original = ast.literal_eval(row_in_info['processed_time_frame_index_list'].values[0])\n",
    "# t_original = [int(i) for i in t_original]; t_original = np.asarray(t_original)\n",
    "# t_new = np.arange(0, 25)\n",
    "\n",
    "# Ecc_aha_sample = np.zeros((16,25))\n",
    "# Err_aha_sample = np.zeros((16,25))\n",
    "\n",
    "\n",
    "# for i in range(16):\n",
    "#     spl_ecc = make_interp_spline(t_original, Ecc_aha[i,:], k=2)  # k=3表示三次样条\n",
    "#     ecc_new = spl_ecc(t_new)\n",
    "\n",
    "#     spl_err = make_interp_spline(t_original, Err_aha[i,:], k=2)  # k=3表示三次样条\n",
    "#     err_new = spl_err(t_new)\n",
    "\n",
    "#     Ecc_aha_sample[i] = ecc_new\n",
    "#     Err_aha_sample[i] = err_new\n",
    "\n",
    "\n",
    "# # # 绘制对比图\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(t_new, Ecc_aha_sample[2,:], label='B-spline Fit', color='red')\n",
    "# plt.plot(t_new,Ecc_aha_sample[2,:], 'yo',markersize=5, label='Interpolated Data')\n",
    "# plt.plot(t_original, Ecc_aha[2,:], 'bo', markersize = 7,label='Original Data')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Strain')\n",
    "# plt.title('B-spline Fit and Original Data Points')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(Ecc_aha_sample)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(correlation_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Correlation Coefficient')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Sample Index')\n",
    "plt.xticks(range(16))\n",
    "plt.yticks(range(16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
